{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sentiment Analysis using a GRU-based encoder with BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wGZ5HGBe0he",
    "outputId": "af34f55a-64f6-40f0-f1fa-0cc45e7b372e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n",
      "\u001b[K     |█████████████▌                  | 834.1 MB 1.3 MB/s eta 0:14:43tcmalloc: large alloc 1147494400 bytes == 0x3ace6000 @  0x7f4f86e90615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
      "\u001b[K     |█████████████████               | 1055.7 MB 1.2 MB/s eta 0:12:56tcmalloc: large alloc 1434370048 bytes == 0x7f33c000 @  0x7f4f86e90615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
      "\u001b[K     |█████████████████████▋          | 1336.2 MB 1.2 MB/s eta 0:08:52tcmalloc: large alloc 1792966656 bytes == 0x416e000 @  0x7f4f86e90615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
      "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:04:09tcmalloc: large alloc 2241208320 bytes == 0x6ef56000 @  0x7f4f86e90615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
      "\u001b[K     |████████████████████████████████| 1982.2 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1982242816 bytes == 0xf48b8000 @  0x7f4f86e8f1e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n",
      "tcmalloc: large alloc 2477809664 bytes == 0x1defb0000 @  0x7f4f86e90615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n",
      "\u001b[K     |████████████████████████████████| 1982.2 MB 5.4 kB/s \n",
      "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.6 MB 7.0 MB/s \n",
      "\u001b[?25hCollecting torchtext==0.9\n",
      "  Downloading torchtext-0.9.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 24.7 MB/s \n",
      "\u001b[?25hCollecting transformers==4.25.1\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 53.8 MB/s \n",
      "\u001b[?25hCollecting torchaudio==0.8.0\n",
      "  Downloading torchaudio-0.8.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 65.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (4.4.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9) (4.64.1)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 74.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (3.8.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (2022.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (21.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 69.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.25.1) (3.0.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9) (2.10)\n",
      "Installing collected packages: torch, tokenizers, huggingface-hub, transformers, torchvision, torchtext, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.0+cu116\n",
      "    Uninstalling torch-1.13.0+cu116:\n",
      "      Successfully uninstalled torch-1.13.0+cu116\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.0+cu116\n",
      "    Uninstalling torchvision-0.14.0+cu116:\n",
      "      Successfully uninstalled torchvision-0.14.0+cu116\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.14.0\n",
      "    Uninstalling torchtext-0.14.0:\n",
      "      Successfully uninstalled torchtext-0.14.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.13.0+cu116\n",
      "    Uninstalling torchaudio-0.13.0+cu116:\n",
      "      Successfully uninstalled torchaudio-0.13.0+cu116\n",
      "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 torch-1.8.0+cu111 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0+cu111 transformers-4.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchtext==0.9 transformers==4.25.1 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkTjtABIfFFL",
    "outputId": "74ef86f5-0387-4678-c1a8-a78537c0e938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import spacy\n",
    "from torchtext.legacy import data, datasets\n",
    "from transformers import BertTokenizer, BertModel\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "print('Using', torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZzSY1aGfhpV",
    "outputId": "dfd4d180-cb22-4bc3-ec8f-94aba6b608d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 512\n",
      "Size of Vocabulary: 30522\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_seq_len = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print('Max sequence length:',max_seq_len)\n",
    "print('Size of Vocabulary:', len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LroyKlDYf2un",
    "outputId": "eb06d24a-9a61-49ca-acf1-f66230f1f427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500 25000 7500\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize = lambda x: tokenizer.tokenize(x)[:max_seq_len-2], preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id, pad_token = tokenizer.pad_token_id, eos_token = tokenizer.eos_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id, batch_first = True, use_vocab = False,)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "train_data, val_data = train_data.split()\n",
    "print(len(train_data), len(test_data), len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYm56-QHhKFm"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "LABEL.build_vocab(train_data)\n",
    "train_loader, val_loader, test_loader = data.BucketIterator.splits((train_data, val_data, test_data), batch_size = batch_size, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duHnZfzNibT8"
   },
   "source": [
    "## GRU + BERT Classification  Model\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEUnnbilkOB7",
    "outputId": "ff353f45-3c88-4851-8f59-985994f332b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "BERT = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jKKrASAiT31"
   },
   "outputs": [],
   "source": [
    "class GRU_BERT(nn.Module):\n",
    "    def __init__(self, BERT, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        emb_dim = BERT.config.to_dict()['hidden_size']\n",
    "        self.BERT = BERT\n",
    "        self.grulayers = nn.GRU(emb_dim, hidden_dim, num_layers = 2, bidirectional = True, dropout = 0.3, batch_first = True)\n",
    "        self.fc = nn.Linear(2*hidden_dim, 1)\n",
    "\n",
    "    def forward(self, text):\n",
    "        with torch.no_grad():\n",
    "            embedded = self.BERT(text)[0] # (seq_len, batch_size) ->  (seq_len, batch_size, emb_dim)\n",
    "\n",
    "        _, hidden_all_layers = self.grulayers(embedded) # hidden = (2*layers, batch_size, hidden_dim) [no. of directions=2]\n",
    "\n",
    "        hidden_last_layer = nn.Dropout(0.3)(torch.cat((hidden_all_layers[-2,:,:], hidden_all_layers[-1,:,:]), dim = 1)) # hidden = (batch_size, 2*hidden_dim)\n",
    "        return self.fc(hidden_last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k08GitKhm8B8",
    "outputId": "69b841f8-516e-4807-ee00-8d49add53925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_BERT(\n",
      "  (BERT): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (grulayers): GRU(768, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GRU_BERT(BERT=BERT, hidden_dim=256).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AceWSc4en0is"
   },
   "source": [
    "### Freeze parameters of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atcxxOnRnVo5",
    "outputId": "3901ec47-ef6c-44e1-8a81-bd847efc0de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grulayers.weight_ih_l0\n",
      "grulayers.weight_hh_l0\n",
      "grulayers.bias_ih_l0\n",
      "grulayers.bias_hh_l0\n",
      "grulayers.weight_ih_l0_reverse\n",
      "grulayers.weight_hh_l0_reverse\n",
      "grulayers.bias_ih_l0_reverse\n",
      "grulayers.bias_hh_l0_reverse\n",
      "grulayers.weight_ih_l1\n",
      "grulayers.weight_hh_l1\n",
      "grulayers.bias_ih_l1\n",
      "grulayers.bias_hh_l1\n",
      "grulayers.weight_ih_l1_reverse\n",
      "grulayers.weight_hh_l1_reverse\n",
      "grulayers.bias_ih_l1_reverse\n",
      "grulayers.bias_hh_l1_reverse\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name.startswith('BERT'):\n",
    "        param.requires_grad = False\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tf7E9Xqn9uT"
   },
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S160k8RloEP1"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    losses, corrects = [], []\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(batch.text)\n",
    "        preds = preds.squeeze(1)\n",
    "        loss = loss_fn(preds, batch.label)\n",
    "\n",
    "        preds = torch.round(torch.sigmoid(preds))\n",
    "        num_correct = (preds == batch.label).sum().float()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        corrects.append(num_correct.item()/len(batch.label))\n",
    "\n",
    "    return sum(losses) / len(train_loader), sum(corrects) / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1RjM1aGoTKk"
   },
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    losses, corrects = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            preds = model(batch.text)\n",
    "            preds = preds.squeeze(1)\n",
    "            loss = loss_fn(preds, batch.label)\n",
    "\n",
    "            preds = torch.round(torch.sigmoid(preds))\n",
    "            num_correct = (preds == batch.label).sum().float()\n",
    "\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            corrects.append(num_correct.item()/len(batch.label))\n",
    "\n",
    "    return sum(losses) / len(loader), sum(corrects) / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-nW0JL9r_PB"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pDM9CXOoTPL",
    "outputId": "fc9932ea-3eaa-4d8b-9d29-dcd250c14bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.449 | Train Acc: 78.33%\n",
      "Val Loss: 0.263 |  Val Acc: 89.00%\n",
      "-------------------------------------------------------\n",
      "Epoch 2\n",
      "Train Loss: 0.288 | Train Acc: 88.10%\n",
      "Val Loss: 0.213 |  Val Acc: 91.60%\n",
      "-------------------------------------------------------\n",
      "Epoch 3\n",
      "Train Loss: 0.249 | Train Acc: 90.05%\n",
      "Val Loss: 0.204 |  Val Acc: 92.21%\n",
      "-------------------------------------------------------\n",
      "Epoch 4\n",
      "Train Loss: 0.221 | Train Acc: 91.25%\n",
      "Val Loss: 0.222 |  Val Acc: 91.67%\n",
      "-------------------------------------------------------\n",
      "CPU times: user 30min 36s, sys: 24min 34s, total: 55min 10s\n",
      "Wall time: 55min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(4):\n",
    "    train_loss, train_acc = train()\n",
    "    val_loss, val_acc = evaluate(val_loader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), './gru_with_bert.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.3f} |  Val Acc: {val_acc*100:.2f}%')\n",
    "    print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rvWOIVXsDmC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uMSqAGvsFWO",
    "outputId": "50392b86-c8f7-4178-93a8-b46a194c8771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.202 | Test Acc: 91.97%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./gru_with_bert.pth'))\n",
    "test_loss, test_acc = evaluate(test_loader)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIYosI84qGfg",
    "outputId": "ab84c4a7-8736-44f2-c7ad-4a9560dd0e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.920813798904419\n",
      "0.1342366337776184\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.tokenize(text)[:max_seq_len-2]\n",
    "    numericalized_tokens = [tokenizer.cls_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [tokenizer.sep_token_id]\n",
    "    inp_text = torch.LongTensor(numericalized_tokens).unsqueeze(0).to(device)\n",
    "    pred = torch.sigmoid(model(inp_text))\n",
    "\n",
    "    return pred.item()\n",
    "print(sentiment_analysis('Good morning Bangalore, great to see a bright and sunny day here.'))\n",
    "print(sentiment_analysis('Me neither! I am so annoyed because my laptop is new, and yet I have not been able to get this new OS to work.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fe_kuj0K5jxB",
    "outputId": "53525f4c-cca2-4a68-cc2e-984bcbada8af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9939267039299011\n",
      "0.01869475655257702\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_analysis('This film is great!'))\n",
    "print(sentiment_analysis('This film is terrible!'))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
